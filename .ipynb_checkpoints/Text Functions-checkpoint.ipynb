{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"sample.txt\"\n",
    "text = open(file, encoding='utf-8').read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'text', 'document', '.', '\\n\\n', 'It', 'is', 'simple', ',', 'so', 'I', 'can', 'easily', 'figure', 'out', 'its', 'stats', '.', '\\n\\n', '\"', 'This', 'is', 'a', 'line', 'of', 'dialogue', '.', '\"', '\\n\\n', 'This', 'is', 'not', '.', '\\n\\n', '\"', 'This', 'is', 'a', 'more', 'complicated', 'line', 'of', 'dialogue', ',', '\"', 'I', 'say', ',', '\"', 'because', 'it', 'spans', 'a', 'speech', 'tag', '.', 'That', 'may', 'be', 'a', 'problem', 'for', 'my', 'program', '.', '\"', '\\n\\n', 'Here', 'is', 'a', 'simple', 'sentence', '.', '\\n\\n', 'Here', ',', 'if', 'you', 'care', 'to', 'look', ',', 'is', 'what', 'you', 'might', 'call', ',', 'if', 'you', \"'re\", 'so', 'inclined', ',', 'a', 'complex', 'sentence', '.', 'It', 'has', 'many', 'more', 'commas', 'than', 'my', 'other', 'sentences', '.', 'Those', 'do', 'not', 'have', 'as', 'many', 'commas', 'as', 'that', 'one', '.', '\\n\\n', '\"', 'Here', 'are', 'some', 'more', 'examples', 'of', 'dialogue', ',', '\"', 'I', 'say', '.', '\"', 'They', 'should', 'cover', 'all', 'the', 'possibilities', '.', '\"', '\\n\\n', 'This', '...', 'might', 'be', 'a', 'problem', '.', 'How', 'will', 'it', 'handle', 'things', '...', '?', 'I', 'do', \"n't\", 'know', '.', '\\n\\n', 'And', 'this', '....', '\\n\\n', 'What', 'does', 'it', 'think', 'of', 'it', '?']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_quotations = [token.text for token in doc if (not token.is_punct or token.text=='\"') and not token.text==\"\\n\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 41 0.3178294573643411\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "diag_count = 0\n",
    "diag = False\n",
    "for i in words_with_quotations:\n",
    "    if i == '\"':\n",
    "        diag = not diag\n",
    "        continue\n",
    "    if diag:\n",
    "        diag_count += 1\n",
    "    word_count += 1\n",
    "    \n",
    "print(word_count, diag_count, diag_count / word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dialogue_proportion(doc):\n",
    "    \"\"\"Takes a spacy doc and returns a 3-tuple of word count, dialogue word count, and the proportion of dialogue to total.\n",
    "    \"\"\"\n",
    "    words_with_quotations = [token.text for token in doc if (not token.is_punct or token.text=='\"' or token.text!=\"\\n\\n\" or token.text!=\"\\n\")]\n",
    "    word_count = 0\n",
    "    diag_count = 0\n",
    "    diag = False\n",
    "    for i in words_with_quotations:\n",
    "        if i == '\"':\n",
    "            diag = not diag\n",
    "            continue\n",
    "        if diag:\n",
    "            diag_count += 1\n",
    "        word_count += 1\n",
    "    \n",
    "    return (word_count, diag_count, word_count/diag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "This is a text document.\n",
      "\n",
      "\n",
      "It is simple, so I can easily figure out its stats.\n",
      "\n",
      "\n",
      "\"This is a line of dialogue.\"\n",
      "\n",
      "\n",
      "This is not.\n",
      "\n",
      "\n",
      "\"This is a more complicated line of dialogue,\" I say, \"because it spans a speech tag.\n",
      "That may be a problem for my program.\"\n",
      "\n",
      "\n",
      "Here is a simple sentence.\n",
      "\n",
      "\n",
      "Here, if you care to look, is what you might call, if you're so inclined, a complex sentence.\n",
      "It has many more commas than my other sentences.\n",
      "Those do not have as many commas as that one.\n",
      "\n",
      "\n",
      "\"Here are some more examples of dialogue,\" I say.\n",
      "\"They should cover all the possibilities.\"\n",
      "\n",
      "\n",
      "This... might be a problem.\n",
      "How will it handle things...?\n",
      "I don't know.\n",
      "\n",
      "\n",
      "And this....\n",
      "\n",
      "\n",
      "What does it think of it?\n"
     ]
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "print(len(sentences))\n",
    "for i in sentences:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_text_on_period(text):\n",
    "    chunks = []\n",
    "    while len(text) > 60000:\n",
    "        split_at = 50000\n",
    "        while text[split_at] != \".\":\n",
    "            split_at += 1\n",
    "        chunks.append(text[0:split_at+1])\n",
    "        text = text[split_at+1:]\n",
    "    chunks.append(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HERE'S A CHUNK \n",
      "\n",
      "209\n",
      "This is a text document.\n",
      "\n",
      "It is simple, so I can easily figure out its stats.\n",
      "\n",
      "\"This is a line of dialogue.\"\n",
      "\n",
      "This is not.\n",
      "\n",
      "\"This is a more complicated line of dialogue,\" I say, \"because it spans a speech tag.\n",
      "\n",
      " HERE'S A CHUNK \n",
      "\n",
      "211\n",
      " That may be a problem for my program.\"\n",
      "\n",
      "Here is a simple sentence.\n",
      "\n",
      "Here, if you care to look, is what you might call, if you're so inclined, a complex sentence. It has many more commas than my other sentences.\n",
      "\n",
      " HERE'S A CHUNK \n",
      "\n",
      "213\n",
      " Those do not have as many commas as that one.\n",
      "\n",
      "\"Here are some more examples of dialogue,\" I say. \"They should cover all the possibilities.\"\n",
      "\n",
      "This... might be a problem. How will it handle things...? I don't know.\n",
      "\n",
      " HERE'S A CHUNK \n",
      "\n",
      "41\n",
      "\n",
      "\n",
      "And this....\n",
      "\n",
      "What does it think of it?\n"
     ]
    }
   ],
   "source": [
    "def chunk_test(text):\n",
    "    chunks = []\n",
    "    while len(text) > 250:\n",
    "        split_at = 200\n",
    "        while text[split_at] != \".\":\n",
    "            split_at += 1\n",
    "        chunks.append(text[0:split_at+1])\n",
    "        text = text[split_at+1:]\n",
    "    chunks.append(text)\n",
    "    return chunks\n",
    "\n",
    "for i in chunk_test(text):\n",
    "    print(\"\\n HERE'S A CHUNK \\n\")\n",
    "    print(len(i))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "para_count = 1\n",
    "for i in [token.text for token in doc]:\n",
    "    if i == \"\\n\\n\" or i == \"\\n\":\n",
    "        para_count += 1\n",
    "print(para_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'be', 'a', 'text', 'document', '-PRON-', 'be', 'simple', 'so', '-PRON-', 'can', 'easily', 'figure', 'out', '-PRON-', 'stat', 'this', 'be', 'a', 'line', 'of', 'dialogue', 'this', 'be', 'not', 'this', 'be', 'a', 'more', 'complicated', 'line', 'of', 'dialogue', '-PRON-', 'say', 'because', '-PRON-', 'span', 'a', 'speech', 'tag', 'that', 'may', 'be', 'a', 'problem', 'for', '-PRON-', 'program', 'here', 'be', 'a', 'simple', 'sentence', 'here', 'if', '-PRON-', 'care', 'to', 'look', 'be', 'what', '-PRON-', 'may', 'call', 'if', '-PRON-', 'be', 'so', 'inclined', 'a', 'complex', 'sentence', '-PRON-', 'have', 'many', 'more', 'comma', 'than', '-PRON-', 'other', 'sentence', 'those', 'do', 'not', 'have', 'as', 'many', 'comma', 'as', 'that', 'one', 'here', 'be', 'some', 'more', 'example', 'of', 'dialogue', '-PRON-', 'say', '-PRON-', 'should', 'cover', 'all', 'the', 'possibility', 'this', 'may', 'be', 'a', 'problem', 'how', 'will', '-PRON-', 'handle', 'thing', '-PRON-', 'do', 'not', 'know', 'and', 'this', 'what', 'do', '-PRON-', 'think', 'of', '-PRON-']\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print([i.lemma_ for i in doc if not i.is_punct and i.text not in [\"\\n\", \"\\n\\n\"]])\n",
    "print(len(set([i.lemma_ for i in doc if not i.is_punct and i.text not in [\"\\n\", \"\\n\\n\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
